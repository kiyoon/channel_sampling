{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44eb80d-bdd5-4f1f-954f-c8c10301d679",
   "metadata": {
    "tags": []
   },
   "source": [
    "The beauty of this framework is that it is very generic and customisable, so you can run using image (or any) data with image models too!\n",
    "Let's infer the ImageNet data using the ResNet50 network.  \n",
    "\n",
    "IMPORTANT: Prepare the ImageNet dataset as follows (no automated script given in the Notebook):\n",
    "- `data/ILSVRC2012/images/val/*.JPEG`  \n",
    "- `data/ILSVRC2012/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt`\n",
    "- `data/ILSVRC2012/ILSVRC2012_devkit_t12/data/meta.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b00c0c1-2cb7-41fa-aff9-916f779a8cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYVIDEOAI_DIR=/home/kiyoon/project/PyVideoAI\n",
      "env: DATA_DIR=/home/kiyoon/project/PyVideoAI/data\n"
     ]
    }
   ],
   "source": [
    "## IMPORTANT: You must change path values in `00-storage_location.py` before executing below.\n",
    "# Environments for future use\n",
    "\n",
    "from pyvideoai.config import PYVIDEOAI_DIR, DATA_DIR\n",
    "%env PYVIDEOAI_DIR=$PYVIDEOAI_DIR\n",
    "%env DATA_DIR=$DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9a822-463e-4ab6-b19d-a1f176bda1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation split CSV file\n",
    "%run \"$PYVIDEOAI_DIR/tools/datasets/generate_imagenet_splits.py\" \"$DATA_DIR/ILSVRC2012/ILSVRC2012_devkit_t12/data/meta.mat\" \"$DATA_DIR/ILSVRC2012/splits\" -v \"$DATA_DIR/ILSVRC2012/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c762f-6e2b-4841-91c3-82a299e00600",
   "metadata": {},
   "source": [
    "Now we have our datasets processed. Pretty simple!\n",
    "We want to use three config files.  \n",
    "- `imagenet.py` in `dataset_configs/ch_image`,  \n",
    "- `resnet50.py` in `model_configs/ch_image`,  \n",
    "- `imagenet/crop224_5scrop_imagenetpretrained.py` in `exp_configs/ch_inference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf4ff2-68f2-4f49-a76a-eef25f45ef8a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# `-m multicrop` will make it perform multicrop evaluation.\n",
    "# `-c:d image` indicates that the dataset_config file is located in `ch_image` directory.\n",
    "# `-c:m image` indicates that the model_config file is located in `ch_image` directory.\n",
    "# `-c:e inference` indicates that the exp_config file is located in `ch_inference` directory.\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "!\"$PYVIDEOAI_DIR/tools/run_singlenode.sh\" eval 1 -D imagenet -c:d image -M resnet50 -c:m image -E crop224_5scrop_imagenetpretrained -c:e inference -m multicrop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2c99b-28b0-4b5a-b8d5-ff8ec3ecd8cd",
   "metadata": {},
   "source": [
    "You can do similar visualisations as the second tutorial (inference on HMDB)!  \n",
    "Save predictions, generate confusion matrix, and so on.  \n",
    "As this is exactly the same as the previous tutorial, we'll skip this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
